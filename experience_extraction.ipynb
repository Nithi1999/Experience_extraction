{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Setup Environment**\n",
        "\n",
        " Installing necessary libraries\n"
      ],
      "metadata": {
        "id": "3MbjUSQHzJHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KELMNd5lhBFy"
      },
      "outputs": [],
      "source": [
        "\n",
        "!apt update\n",
        "!apt install -y python3-venv\n",
        "\n",
        "!pip install spacy==3.7.2\n",
        "!pip install spacy-transformers\n",
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "\n",
        "\n",
        "!python -m spacy download en_core_web_trf\n",
        "\n",
        "\n",
        "!pip install numpy>=1.25.0 pandas-stubs==2.0.3.230814\n",
        "\n",
        "\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
        "\n",
        "# !pip install torch\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "6Y5Fj2iJhO03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCEU9PRUvsvg"
      },
      "outputs": [],
      "source": [
        "!pip install spacy==3.7.2\n",
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm4woAdC0FNG"
      },
      "outputs": [],
      "source": [
        "!pip install spacy-transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqzjSgE0zQSk"
      },
      "outputs": [],
      "source": [
        "# import spacy\n",
        "# from spacy.tokens import DocBin\n",
        "# from tqdm import tqdm\n",
        "# import os\n",
        "# import json\n",
        "# import random\n",
        "\n",
        "# # Load English blank model\n",
        "# nlp = spacy.blank(\"en\")\n",
        "\n",
        "# # Function to convert data to .spacy format\n",
        "# def convert_to_spacy_format(data):\n",
        "#     db = DocBin()\n",
        "#     for text, annot in tqdm(data):\n",
        "#         doc = nlp.make_doc(text)\n",
        "#         ents = []\n",
        "#         for start, end, label in annot[\"entities\"]:\n",
        "#             span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "#             if span is None:\n",
        "#                 print(\"Skipping entity\")\n",
        "#             else:\n",
        "#                 ents.append(span)\n",
        "#         doc.ents = ents\n",
        "#         db.add(doc)\n",
        "#     return db\n",
        "\n",
        "# # Load all JSON files from the \"train\" directory\n",
        "# train_dir = \"/experience_extraction/train\"\n",
        "# all_data = []\n",
        "# for filename in os.listdir(train_dir):\n",
        "#     if filename.endswith(\".json\"):\n",
        "#         with open(os.path.join(train_dir, filename)) as f:\n",
        "#             data = json.load(f)\n",
        "#             all_data.extend(data[\"annotations\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "Of5g-Pb10Ad6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import json\n",
        "import os\n",
        "\n",
        "def convert_to_spacy(json_spec):\n",
        "    nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "    db = DocBin() # create a DocBin object\n",
        "    dir, file_name = os.path.split(json_spec)\n",
        "    with open(json_spec) as json_f:\n",
        "        data = json.load(json_f)\n",
        "\n",
        "    td = [item for item in data['annotations'] if item]\n",
        "    for text, annot in tqdm(td): # data in previous format\n",
        "        doc = nlp.make_doc(text) # create doc object from text\n",
        "        ents = []\n",
        "        if not annot[\"entities\"]:\n",
        "          continue\n",
        "\n",
        "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "            if span is None:\n",
        "                print(\"Skipping entity\")\n",
        "            else:\n",
        "                ents.append(span)\n",
        "        doc.ents = ents # label the text with the ents\n",
        "        db.add(doc)\n",
        "\n",
        "    db.to_disk(os.path.join(dir, f\"{file_name.split('.')[0]}.spacy\"))\n"
      ],
      "metadata": {
        "id": "BFpoGkKBJgGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_spacy(\"/experience_extraction/training_data/training/annotated_dataset.json\")"
      ],
      "metadata": {
        "id": "vhj6sJQAJkk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zem4-2qGaQdY"
      },
      "outputs": [],
      "source": [
        "# # Shuffle the data\n",
        "# random.shuffle(all_data)\n",
        "\n",
        "# # Split data into training and validation sets (80% training, 20% validation)\n",
        "# split_idx = int(0.8 * len(all_data))\n",
        "# train_data = all_data[:split_idx]\n",
        "# val_data = all_data[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tpt0ZgTaUHC"
      },
      "outputs": [],
      "source": [
        "# train_db = convert_to_spacy_format(train_data)\n",
        "# val_db = convert_to_spacy_format(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDmiVugmXQlp"
      },
      "outputs": [],
      "source": [
        "# # Save .spacy format files\n",
        "# train_db.to_disk(\"/experience_extraction/training_data/training/training_data.spacy\")\n",
        "# val_db.to_disk(\"/experience_extraction/training_data/validation/validation_data.spacy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training configuration**"
      ],
      "metadata": {
        "id": "rQCkz0ZC0OUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZgQOYgX6rzx"
      },
      "outputs": [],
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmxZAFnFuTn2"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy init config config.cfg --lang en --pipeline ner --optimize accuracy --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkOnUgzKldFs"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wSRLPL3q_aV"
      },
      "outputs": [],
      "source": [
        "# !pip install spacy==3.7.2\n",
        "# !pip install spacy-transformers\n",
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cupy"
      ],
      "metadata": {
        "id": "A72a0NDznhl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Train the model***\n"
      ],
      "metadata": {
        "id": "ba6ivUb90Ywi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWdiiscOXcgp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./training_data/training/annotated_dataset.spacy --paths.dev ./training_data/validation/annotated_dataset.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the model**"
      ],
      "metadata": {
        "id": "pK4Lgaz505HN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF_GBJxsxERt"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp_ner = spacy.load(\"./model-best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCWTyYbBxHna"
      },
      "outputs": [],
      "source": [
        "doc = nlp_ner('''\n",
        "\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d1Baw9PxLL3"
      },
      "outputs": [],
      "source": [
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp = []\n",
        "if doc.ents:\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ == \"EXPERIENCE\":\n",
        "      print(ent.text)\n",
        "\n",
        "  print(doc.ents)"
      ],
      "metadata": {
        "id": "PFz6oIRPZVIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training import offsets_to_biluo_tags\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.training.example import Example\n",
        "\n",
        "nlp = spacy.load(\"./model-best\")\n",
        "\n",
        "eval_data = DocBin().from_disk(\"./training_data/validation/validation_data.spacy\")\n",
        "\n",
        "docs = list(eval_data.get_docs(nlp.vocab))\n",
        "\n",
        "for doc in docs:\n",
        "    ents = [(ent.start, ent.end, ent.label_) for ent in doc.ents]\n",
        "    biluo_tags = offsets_to_biluo_tags(doc, ents)\n",
        "    if '-' in biluo_tags:\n",
        "        print(f\"Misaligned entities in text: {doc.text}\")\n",
        "        print(f\"Entities: {ents}\")\n",
        "        print(f\"BILUO Tags: {biluo_tags}\")\n",
        "\n",
        "examples = []\n",
        "for doc in docs:\n",
        "    ents = [(ent.start, ent.end, ent.label_) for ent in doc.ents]\n",
        "    if '-' not in offsets_to_biluo_tags(doc, ents):\n",
        "        example = Example.from_dict(doc, {\"entities\": ents})\n",
        "        examples.append(example)\n",
        "\n",
        "scorer = nlp.evaluate(examples)\n",
        "\n",
        "def safe_print_metric(scorer, metric_name, metric_display_name):\n",
        "    value = scorer.get(metric_name)\n",
        "    if value is not None:\n",
        "        print(f\"{metric_display_name}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{metric_display_name}: N/A\")\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "safe_print_metric(scorer, 'ents_f', \"Entities F1-score (ENTS_F)\")\n",
        "safe_print_metric(scorer, 'ents_p', \"Entities Precision (ENTS_P)\")\n",
        "safe_print_metric(scorer, 'ents_r', \"Entities Recall (ENTS_R)\")\n",
        "\n",
        "print(\"Available keys in scorer:\", scorer.keys())\n",
        "\n",
        "safe_print_metric(scorer, 'token_acc', \"Token Accuracy (Token Acc)\")\n",
        "safe_print_metric(scorer, 'tags_acc', \"Tags Accuracy (Tags Acc)\")\n",
        "safe_print_metric(scorer, 'uas', \"Unlabeled Attachment Score (UAS)\")\n",
        "safe_print_metric(scorer, 'las', \"Labeled Attachment Score (LAS)\")\n"
      ],
      "metadata": {
        "id": "5D_MpBWlgxLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QOIVmO6oA3ij6H4OWgozQ4cmsNZEGROs",
      "authorship_tag": "ABX9TyPVZVNEzbrVutrMS/hEJjbr"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}